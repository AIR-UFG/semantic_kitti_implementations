{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75996e1c-f85e-439a-ada3-2bae6475f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f52d5df-e9a3-425e-99c2-b47919f47929",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from collections import defaultdict\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac6334-3e3c-48fa-a772-207a5cbfb911",
   "metadata": {},
   "source": [
    "Only for examples in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac1ddb7-00e6-43df-8373-320429bc1796",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "from semantic_kitti_implementations import mvlidar_model\n",
    "from semantic_kitti_implementations import data\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "126b30d0-87bf-4080-8c71-56e018c1911f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#| export\n",
    "DEVICE = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {DEVICE} device\")\n",
    "PIN_MEMORY = True if DEVICE == \"cuda\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480fa5c-2ab5-4d7a-a254-506537dafdee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Learner:\n",
    "    def __init__(self, model, optimizer, lr, num_classes):\n",
    "        self.model = model(num_classes).to(DEVICE)\n",
    "        self.optimizer = optimizer(self.model.parameters(), lr=lr)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def update(self, loss):\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        self.optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e7d1fba-489c-4505-92c8-1ba6d479e8c2",
   "metadata": {},
   "source": [
    "An example of how you should create the learner object, remember to chose the correct hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f2b13-8d44-4abc-af8d-017ed3caf167",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "learner = Learner(model=mvlidar_model.MVLidar, optimizer=Adam, lr=0.01, num_classes=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16acc86-083e-49a9-be1e-d45572d0825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Evaluator:\n",
    "    def __init__(self, loss_fn):\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    def get_loss(self, y, y_hat):\n",
    "        bin_mask_train = (y !=0).int()\n",
    "        loss = self.loss_fn(y_hat, y)\n",
    "        loss = loss * bin_mask_train\n",
    "        loss = loss.mean()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5ad9ba-6e47-439b-bdd1-3e985e4a23a9",
   "metadata": {},
   "source": [
    "An example of how you should create the evaluator object, remember to chose the correct hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87970f4f-5675-4132-987f-8ff8c3352ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| eval: false\n",
    "evaluator = Evaluator(loss_fn=CrossEntropyLoss(reduction=\"none\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5496e5-dda4-4e9f-b96f-e5251a013089",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Trainer:\n",
    "    def __init__(self, train_dataset, test_dataset, learner: Learner, evaluator: Evaluator, batch_size):\n",
    "        self.train_dataset = train_dataset\n",
    "        self.test_dataset = test_dataset\n",
    "        self.learner = learner\n",
    "        self.batch_size = batch_size\n",
    "        self.evaluator = evaluator\n",
    "        self.log = defaultdict()\n",
    "\n",
    "    def train(self):\n",
    "        self.learner.model.train()\n",
    "        dataloader = DataLoader(self.train_dataset, batch_size=self.batch_size)\n",
    "        epoch_loss = 0\n",
    "        num_batches = len(dataloader)\n",
    "\n",
    "        for batch_idx, (X,y) in enumerate(dataloader):\n",
    "            (X,y) = (X.to(DEVICE), y.to(DEVICE))\n",
    "            y_hat = self.learner.predict(X)\n",
    "            loss = self.evaluator.get_loss(y,y_hat)\n",
    "            epoch_loss += loss.item()\n",
    "            self.learner.update(loss)\n",
    "\n",
    "        # perguntar a divisão\n",
    "        self.log['train_loss'] = epoch_loss / num_batches\n",
    "\n",
    "    def test(self):\n",
    "        self.learner.model.eval()\n",
    "        dataloader = DataLoader(self.test_dataset, batch_size=self.batch_size)\n",
    "        epoch_loss = 0\n",
    "        num_batches = len(dataloader)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for X,y in dataloader:\n",
    "                (X,y) = (X.to(DEVICE), y.to(DEVICE))\n",
    "                y_hat = self.learner.predict(X)\n",
    "                loss = self.evaluator.get_loss(y,y_hat)\n",
    "                epoch_loss += loss.item()\n",
    "\n",
    "        # perguntar a divisão\n",
    "        self.log['test_loss'] = epoch_loss / num_batches\n",
    "\n",
    "    def run(self, wandb, n_epochs: int):\n",
    "        for t in range(n_epochs):\n",
    "            self.train()\n",
    "            self.test()\n",
    "            wandb.log({\"train_loss\": self.log[\"train_loss\"], \"test_loss\": self.log[\"test_loss\"]})\n",
    "            if (t+1) % 20 == 0:\n",
    "                print(f\"Epoch {t+1}\\n------------\")\n",
    "                print(f\"Train loss {self.log['train_loss']}\\nTest loss {self.log['test_loss']}\")\n",
    "        print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b943c7e5-aa99-40fd-b577-364d749fa9f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
